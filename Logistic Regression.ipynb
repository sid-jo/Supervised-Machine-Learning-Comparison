{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f11817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit feature space: (10000, 4)\n",
      "Fruit label space (10000,)\n",
      "Chess feature space: (20058, 373)\n",
      "Chess label space (20058,)\n",
      "Music feature space: (200, 28)\n",
      "Music label space (200,)\n",
      "Lepiota feature space: (8124, 46)\n",
      "Lepiota label space: (8124,)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "np.set_printoptions(suppress = True)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "# Importing data sets\n",
    "from data_import import load_fruits, load_chess, load_music, load_lepiota\n",
    "\n",
    "fruit_X, fruit_Y = load_fruits()\n",
    "chess_X, chess_Y = load_chess()\n",
    "music_X, music_Y = load_music()\n",
    "lep_X, lep_Y = load_lepiota()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea2071",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f96ba9",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53290786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to truncate sigmoid inputs\n",
    "def truncate(val):\n",
    "    return np.maximum(-50, np.minimum(val, 50))\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Incurs error for incorrect predictions\n",
    "def judge(a, b):\n",
    "    if a != b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# Generates prediction based on probability outcome from sigmoid    \n",
    "def logistic(x, W, b, thresh):\n",
    "    if sigmoid(W.T @ x + b) >= thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Calculate error given feature vectors X and labels Y\n",
    "def calc_error(X, Y, W, b, thresh = 0.5):\n",
    "    e = np.array([])\n",
    "    preds = np.array([])\n",
    "    for xi, yi in zip(X, Y):\n",
    "        pred = logistic(xi, W, b, thresh)\n",
    "        preds = np.append(preds, pred)\n",
    "        e = np.append(e, judge(pred, yi))\n",
    "    acc = np.count_nonzero(e == 0) / e.shape[0]\n",
    "    e = e.mean()\n",
    "    \n",
    "    return e, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic loss\n",
    "def L_W_b(X, Y, W, b):\n",
    "    loss = -1 * np.ones(X.shape[0]) * np.log(sigmoid(truncate(Y * (X @ W + (b * np.ones(X.shape[0]))))))\n",
    "    return loss\n",
    "\n",
    "# Gradient for logistic loss\n",
    "def grad_L_W_b(X, Y, W, b):\n",
    "\n",
    "    grad_W = -X.T @ ((1 - sigmoid(Y * (X @ W + (b * np.ones(X.shape[0]))))) * Y)\n",
    "    grad_b = -1 * np.ones(X.shape[0]).T @ ((1 - sigmoid(Y * (X @ W + (b * np.ones(X.shape[0]))))) * Y)\n",
    "\n",
    "    return grad_W, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dabf64",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression learning algorithm; gradient descent\n",
    "def fit_log_reg(X, Y, iterations = 5000):\n",
    "    losses = []           # Error history\n",
    "    lam = 0.001           # Learning rate/step-size, fixed\n",
    "    W = np.zeros(X.shape[1])\n",
    "    b = 0.0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        grad_W, grad_b = grad_L_W_b(X, Y, W, b)\n",
    "        \n",
    "        W = W - lam * grad_W\n",
    "        b = b - lam * grad_b\n",
    "\n",
    "        # Tracking training losses\n",
    "        cur_loss = L_W_b(X, Y, W, b).sum()\n",
    "        losses.append(cur_loss)\n",
    "    \n",
    "    return W, b, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7054b",
   "metadata": {},
   "source": [
    "###  Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f42f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating average training accuracy for 20/80 split\n",
    "\n",
    "def train_log_reg(X, y, size):\n",
    "    avg_e = 0\n",
    "    avg_acc = 0\n",
    "\n",
    "    for i in np.arange(3):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = size, shuffle = True)\n",
    "        W, b, losses = fit_log_reg(X_train, y_train)\n",
    "        e, acc = calc_error(X_train, y_train, W, b)\n",
    "        avg_e += e\n",
    "        avg_acc += acc\n",
    "        \n",
    "    print(avg_acc / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd296d",
   "metadata": {},
   "source": [
    "### Cross-Validation and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines labels (Y) as another column to feature set (X)\n",
    "def join_data(X, Y):\n",
    "    return np.hstack((X, Y.reshape(Y.shape[0], 1)))\n",
    "\n",
    "def tune_threshold(X, y):\n",
    "    \n",
    "    # Joining and splitting data\n",
    "    data = join_data(X, y)    \n",
    "    kf = KFold(n_splits = 5, shuffle = True)\n",
    "    thresh_list = np.arange(0, 1.05, 0.05)\n",
    "    \n",
    "    \n",
    "    # Assessing possible thresholds at 0.01 increments\n",
    "    for thresh in thresh_list:\n",
    "        val_accs = np.array([])\n",
    "        print('Testing threshold: {}'.format(thresh))\n",
    "        for trial in np.arange(3):\n",
    "            accs = np.array([])\n",
    "            errs = np.array([])\n",
    "\n",
    "            for train_index, test_index in kf.split(data):\n",
    "                W, b, losses = fit_log_reg(data[train_index][:, :data.shape[1] - 1], data[train_index][:, -1])\n",
    "                e, acc = calc_error(data[test_index][:, :data.shape[1] - 1], data[test_index][:, -1], W, b, thresh)\n",
    "                accs = np.append(accs, acc)\n",
    "            val_accs = np.append(val_accs, accs.mean())\n",
    "        if val_accs.mean() > best_acc:\n",
    "            best_thresh = thresh\n",
    "            best_acc = val_accs.mean()\n",
    "\n",
    "    print('Best threshold: {}'.format(best_thresh))\n",
    "    return round(best_thresh, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850b15b",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d97d67",
   "metadata": {},
   "source": [
    "### Generating Training Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d900dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_reg(fruit_X, fruit_Y, 0.8)\n",
    "train_log_reg(fruit_X, fruit_Y, 0.5)\n",
    "train_log_reg(fruit_X, fruit_Y, 0.2)\n",
    "\n",
    "train_log_reg(chess_X, chess_Y, 0.8)\n",
    "train_log_reg(chess_X, chess_Y, 0.5)\n",
    "train_log_reg(chess_X, chess_Y, 0.2)\n",
    "\n",
    "train_log_reg(music_X, music_Y, 0.8)\n",
    "train_log_reg(music_X, music_Y, 0.5)\n",
    "train_log_reg(music_X, music_Y, 0.2)\n",
    "\n",
    "train_log_reg(lep_X, lep_Y, 0.8)\n",
    "train_log_reg(lep_X, lep_Y, 0.5)\n",
    "train_log_reg(lep_X, lep_Y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec86c66",
   "metadata": {},
   "source": [
    "## 20/80 Splits for Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24839e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fruits\n",
    "fruit_X_train20, fruit_X_test80, fruit_Y_train20, fruit_Y_test80 = train_test_split(fruit_X, fruit_Y, test_size = 0.8, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(fruit_X_train20, fruit_Y_train20)\n",
    "W, b, losses = fit_log_reg(fruit_X_train20, fruit_Y_train20)\n",
    "e, f_acc = calc_error(fruit_X_test80, fruit_Y_test80, W, b, opt_thresh)\n",
    "\n",
    "# Chess\n",
    "chess_X_train20, chess_X_test80, chess_Y_train20, chess_Y_test80 = train_test_split(chess_X, chess_Y, test_size = 0.8, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(chess_X_train20, chess_Y_train20)\n",
    "W, b, losses = fit_log_reg(chess_X_train20, chess_Y_train20)\n",
    "e, c_acc = calc_error(chess_X_test80, chess_Y_test80, W, b, opt_thresh)\n",
    "\n",
    "# Music\n",
    "music_X_train20, music_X_test80, music_Y_train20, music_Y_test80 = train_test_split(music_X, music_Y, test_size = 0.8, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(music_X_train20, music_Y_train20)\n",
    "W, b, losses = fit_log_reg(music_X_train20, music_Y_train20)\n",
    "e, m_acc = calc_error(music_X_test80, music_Y_test80, W, b, opt_thresh)\n",
    "\n",
    "# Lepiota\n",
    "lep_X_train20, lep_X_test80, lep_Y_train20, lep_Y_test80 = train_test_split(lep_X, lep_Y, test_size = 0.8, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(lep_X_train20, lep_Y_train20)\n",
    "W, b, losses = fit_log_reg(lep_X_train20, lep_Y_train20)\n",
    "e, l_acc = calc_error(lep_X_test80, lep_Y_test80, W, b, opt_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da903fa",
   "metadata": {},
   "source": [
    "## 50/50 Splits for Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17035a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fruits\n",
    "fruit_X_train50, fruit_X_test50, fruit_Y_train50, fruit_Y_test50 = train_test_split(fruit_X, fruit_Y, test_size = 0.5, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(fruit_X_train50, fruit_Y_train50)\n",
    "W, b, losses = fit_log_reg(fruit_X_train50, fruit_Y_train50)\n",
    "e, f_acc = calc_error(fruit_X_test50, fruit_Y_test50, W, b, opt_thresh)\n",
    "\n",
    "# Chess\n",
    "chess_X_train50, chess_X_test50, chess_Y_train50, chess_Y_test50 = train_test_split(chess_X, chess_Y, test_size = 0.5, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(chess_X_train50, chess_Y_train50)\n",
    "W, b, losses = fit_log_reg(chess_X_train50, chess_Y_train50)\n",
    "e, c_acc = calc_error(chess_X_test50, chess_Y_test50, W, b, opt_thresh)\n",
    "\n",
    "# Music\n",
    "music_X_train50, music_X_test50, music_Y_train50, music_Y_test50 = train_test_split(music_X, music_Y, test_size = 0.5, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(music_X_train50, music_Y_train50)\n",
    "W, b, losses = fit_log_reg(music_X_train50, music_Y_train50)\n",
    "e, m_acc = calc_error(music_X_test50, music_Y_test50, W, b, opt_thresh)\n",
    "\n",
    "# Lepiota\n",
    "lep_X_train50, lep_X_test50, lep_Y_train50, lep_Y_test50 = train_test_split(lep_X, lep_Y, test_size = 0.5, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(lep_X_train50, lep_Y_train50)\n",
    "W, b, losses = fit_log_reg(lep_X_train50, lep_Y_train50)\n",
    "e, l_acc = calc_error(lep_X_test50, lep_Y_test50, W, b, opt_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd93020",
   "metadata": {},
   "source": [
    "## 80/20 Splits for Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fruits\n",
    "fruit_X_train80, fruit_X_test20, fruit_Y_train80, fruit_Y_test20 = train_test_split(fruit_X, fruit_Y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(fruit_X_train80, fruit_Y_train80)\n",
    "W, b, losses = fit_log_reg(fruit_X_train80, fruit_Y_train80)\n",
    "e, f_acc = calc_error(fruit_X_test20, fruit_Y_test20, W, b, opt_thresh)\n",
    "\n",
    "# Chess\n",
    "chess_X_train80, chess_X_test20, chess_Y_train80, chess_Y_test20 = train_test_split(chess_X, chess_Y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(chess_X_train80, chess_Y_train80)\n",
    "W, b, losses = fit_log_reg(chess_X_train80, chess_Y_train80)\n",
    "e, c_acc = calc_error(chess_X_test20, chess_Y_test20, W, b, opt_thresh)\n",
    "\n",
    "# Music\n",
    "music_X_train80, music_X_test20, music_Y_train80, music_Y_test20 = train_test_split(music_X, music_Y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(music_X_train80, music_Y_train80)\n",
    "W, b, losses = fit_log_reg(music_X_train80, music_Y_train80)\n",
    "e, m_acc = calc_error(music_X_test20, music_Y_test20, W, b, opt_thresh)\n",
    "\n",
    "# Lepiota\n",
    "lep_X_train80, lep_X_test20, lep_Y_train80, lep_Y_test20 = train_test_split(lep_X, lep_Y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "opt_thresh = tune_threshold(lep_X_train80, lep_Y_train80)\n",
    "W, b, losses = fit_log_reg(lep_X_train80, lep_Y_train80)\n",
    "e, l_acc = calc_error(lep_X_test20, lep_Y_test20, W, b, opt_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f23c8f",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c874709",
   "metadata": {},
   "source": [
    "1. Split data into training and testing splits\n",
    "2. Execute `fit_log_reg()` on the training set\n",
    "    - Runs `log_reg()` on training set, which conducts gradient descent and outputs optimal $W$ and $b$ for given training set\n",
    "    - Calculates training error (using training set and derived parameters for $W$ and $b$)\n",
    "    - Outputs training error\n",
    "3. Repeat step 2 three times and average the training error from each trial;\n",
    "Once training error is determined, run `tune_threshold()` with training data to select optimal threshold for model\n",
    "    - Optimal threshold will be determined using accuracy metric\n",
    "    - For each fold, fit a new $(W, b)$ and run `calc_error()` on remaining 4 folds; record accuracy\n",
    "    - Average all five accuracy measures for a single measure per threshold\n",
    "    - Select threshold with the highest accuracy\n",
    "\n",
    "Fit model to training data again using `fit_log_reg()` and generate predictions/error on **testing data** using the optimal threshold detrmined in the `tune_threshold()` with `calc_error()`\n",
    "\n",
    "\n",
    "For each data split, re-run `tune_threshold()` and execute testing iteration using each trial's best threshold\n",
    "Report all three average validation accuracies and three testing accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce469059",
   "metadata": {},
   "source": [
    "#### Pseudocode\n",
    "\n",
    "1. Initialize $w$ matrix and $b$ vector (zeros) to match the size of the feature space\n",
    "2. Run training loop by calculating the gradient and updating each time (do this 10000 times)\n",
    "\n",
    "From this process, we will get a weight matrix and bias term to use to training calculate the training error\n",
    "\n",
    "\n",
    "3. Take newly determined weights/biases and generate training error using `calc_error()`\n",
    "    - This function would take in the learned weights and calculate a $wx + b$\n",
    "    - This is then passed into the `sigmoid()` function to get probabilities\n",
    "    - Using a Bayesian decision criterion (0.5) classify all the probabilites as 1 or -1\n",
    "    - Pass predictions and G.T. into `judge()` to get number of incorrect predictions\n",
    "    - Pass that into `error_calc()` and it will output the mean of the number of errors (training error) \n",
    "\n",
    "\n",
    "Run this entire algorithm two more times with different 20/80 splits of data (shuffle again)\n",
    "\n",
    "7. Average the three training errors from the trials to get one overall training error for the logistic regression 20/80 split\n",
    "8. Which of the three models should we use for cross-validation/tuning?\n",
    "\n",
    "### Helper functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
